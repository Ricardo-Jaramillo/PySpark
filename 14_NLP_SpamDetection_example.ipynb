{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNaFb8AYHsazydIEihdvsGG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ricardo-Jaramillo/PySpark/blob/main/14_NLP_SpamDetection_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spam detection with NLP in PySpark\n",
        "Let's use what we learned in the previous step and work with NLP techniques to build a model which can predict if a message is a Spam or not."
      ],
      "metadata": {
        "id": "THDt5c8TFFbq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install pyspark"
      ],
      "metadata": {
        "id": "o6C_RJ5FOh1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqjO0nvbSSku",
        "outputId": "1bdb45f3-610f-46ef-d24f-b051c61a2a4e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=7d3950fe6c34e973efbc8b338af87f0be380b617d2803e815a88c71da90a8528\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Donwload the file\n",
        "!wget https://raw.githubusercontent.com/Ricardo-Jaramillo/PySpark/main/datasets/NLP/SMSSpamCollection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCYNYPurGWlb",
        "outputId": "50303add-4fb9-41be-be3a-061e8d25cde8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-04 23:55:05--  https://raw.githubusercontent.com/Ricardo-Jaramillo/PySpark/main/datasets/NLP/SMSSpamCollection\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 477907 (467K) [text/plain]\n",
            "Saving to: ‘SMSSpamCollection’\n",
            "\n",
            "SMSSpamCollection   100%[===================>] 466.71K  2.92MB/s    in 0.2s    \n",
            "\n",
            "2023-10-04 23:55:05 (2.92 MB/s) - ‘SMSSpamCollection’ saved [477907/477907]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necesary libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import length\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.feature import StopWordsRemover\n",
        "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
        "from pyspark.ml.feature import HashingTF, IDF\n",
        "from pyspark.ml.feature import CountVectorizer\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml import Pipeline"
      ],
      "metadata": {
        "id": "u-y5YTr0SUS3"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a Spark Session and read the data"
      ],
      "metadata": {
        "id": "eec3r54yJVTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a session\n",
        "spark = SparkSession.builder.appName('nlp_example').getOrCreate()"
      ],
      "metadata": {
        "id": "aCW88ZyMSibM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in the data file\n",
        "raw_data = spark.read.csv('SMSSpamCollection', inferSchema=True, sep='\\t')"
      ],
      "metadata": {
        "id": "HAnk67cISqPr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the data\n",
        "data = raw_data.withColumnRenamed('_c0', 'class').withColumnRenamed('_c1', 'text')"
      ],
      "metadata": {
        "id": "gobkoQuoH0MW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show data\n",
        "data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BZnEENmIxZr",
        "outputId": "2dae23bf-cb39-4458-abda-819266050b4c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+\n",
            "|class|                text|\n",
            "+-----+--------------------+\n",
            "|  ham|Go until jurong p...|\n",
            "|  ham|Ok lar... Joking ...|\n",
            "| spam|Free entry in 2 a...|\n",
            "|  ham|U dun say so earl...|\n",
            "|  ham|Nah I don't think...|\n",
            "| spam|FreeMsg Hey there...|\n",
            "|  ham|Even my brother i...|\n",
            "|  ham|As per your reque...|\n",
            "| spam|WINNER!! As a val...|\n",
            "| spam|Had your mobile 1...|\n",
            "|  ham|I'm gonna be home...|\n",
            "| spam|SIX chances to wi...|\n",
            "| spam|URGENT! You have ...|\n",
            "|  ham|I've been searchi...|\n",
            "|  ham|I HAVE A DATE ON ...|\n",
            "| spam|XXXMobileMovieClu...|\n",
            "|  ham|Oh k...i'm watchi...|\n",
            "|  ham|Eh u remember how...|\n",
            "|  ham|Fine if thats th...|\n",
            "| spam|England v Macedon...|\n",
            "+-----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply Feature Engineering\n",
        "Let's try to see if adding the length of the message as a feature results in a better performance of the model"
      ],
      "metadata": {
        "id": "2GJ91Rh3Ja1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add column with the length of every mesasge\n",
        "data = data.withColumn('length', length(data['text']))"
      ],
      "metadata": {
        "id": "bOmX1m0VH08H"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the new dataFrame\n",
        "data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMScBoyVIsQY",
        "outputId": "205aeb5c-67cf-45e7-e90c-b8c7cce1e59a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+------+\n",
            "|class|                text|length|\n",
            "+-----+--------------------+------+\n",
            "|  ham|Go until jurong p...|   111|\n",
            "|  ham|Ok lar... Joking ...|    29|\n",
            "| spam|Free entry in 2 a...|   155|\n",
            "|  ham|U dun say so earl...|    49|\n",
            "|  ham|Nah I don't think...|    61|\n",
            "| spam|FreeMsg Hey there...|   147|\n",
            "|  ham|Even my brother i...|    77|\n",
            "|  ham|As per your reque...|   160|\n",
            "| spam|WINNER!! As a val...|   157|\n",
            "| spam|Had your mobile 1...|   154|\n",
            "|  ham|I'm gonna be home...|   109|\n",
            "| spam|SIX chances to wi...|   136|\n",
            "| spam|URGENT! You have ...|   155|\n",
            "|  ham|I've been searchi...|   196|\n",
            "|  ham|I HAVE A DATE ON ...|    35|\n",
            "| spam|XXXMobileMovieClu...|   149|\n",
            "|  ham|Oh k...i'm watchi...|    26|\n",
            "|  ham|Eh u remember how...|    81|\n",
            "|  ham|Fine if thats th...|    56|\n",
            "| spam|England v Macedon...|   155|\n",
            "+-----+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.groupBy('class').mean().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhYJ3EuLI7wt",
        "outputId": "d791defd-8efd-4e68-c0fe-11d313f2cde4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------------+\n",
            "|class|      avg(length)|\n",
            "+-----+-----------------+\n",
            "|  ham|71.45431945307645|\n",
            "| spam|138.6706827309237|\n",
            "+-----+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> We can guess that the length of the msessage has a strong influence on the result of a Spam message. So we'll add it,"
      ],
      "metadata": {
        "id": "rbuDAqqtJB2N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess the Data.\n",
        "\n",
        "We'll create the following objects:\n",
        "* StringIndexer\n",
        "* Vector Assembler\n",
        "* Tokenizer\n",
        "* StopWordsRemover\n",
        "* CountVectorizer\n",
        "* IDF (Inverse Document Frequency)\n",
        "* Vector Assembler"
      ],
      "metadata": {
        "id": "PK7iYHbDJ1Es"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Object creation"
      ],
      "metadata": {
        "id": "2oLg4iR8Q_fi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# StringIndexer\n",
        "ham_spam_to_numeric = StringIndexer(inputCol='class', outputCol='label')"
      ],
      "metadata": {
        "id": "329Rm1rnLDbK"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tokenizer object\n",
        "tokenizer = Tokenizer(inputCol='text', outputCol='token_text')"
      ],
      "metadata": {
        "id": "imeYk3fjJ3zf"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create words remover object\n",
        "stop_remover = StopWordsRemover(inputCol='token_text', outputCol='stop_token')"
      ],
      "metadata": {
        "id": "G_aYjX3fKLi9"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create countVectorizer object\n",
        "count_vec = CountVectorizer(inputCol='stop_token', outputCol='count_vec')"
      ],
      "metadata": {
        "id": "GF4BRXP8KL1w"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create IDF object\n",
        "idf = IDF(inputCol='count_vec', outputCol='tf_idf')"
      ],
      "metadata": {
        "id": "3tGlhGgFKiQY"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VectorAssembler\n",
        "clean_up = VectorAssembler(inputCols=['tf_idf', 'length'], outputCol='features')"
      ],
      "metadata": {
        "id": "q7IdGPqRLET5"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a pipeline to preprocess in a single step\n",
        "We're gonna create our NLP model using the `Pipeline` function.\n",
        "\n",
        "This let's us to concatenate all process into one simple step"
      ],
      "metadata": {
        "id": "g2GRE_DyLc67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the pipeline\n",
        "data_prep_pipeline = Pipeline(stages=[\n",
        "    ham_spam_to_numeric,\n",
        "    tokenizer,\n",
        "    stop_remover,\n",
        "    count_vec,\n",
        "    idf,\n",
        "    clean_up\n",
        "])"
      ],
      "metadata": {
        "id": "NtLN4-ynNd0M"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess\n",
        "Get a clean_data DataFrame"
      ],
      "metadata": {
        "id": "vt6a4v8rPGAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass our data to the pipeline we just created\n",
        "cleaner = data_prep_pipeline.fit(data)"
      ],
      "metadata": {
        "id": "zcbvy7J7Npvh"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the data\n",
        "clean_data = cleaner.transform(data)"
      ],
      "metadata": {
        "id": "YqkCGzpdN_1L"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show clean_data\n",
        "clean_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILeKONhfO2kN",
        "outputId": "19e6c787-90d4-4b58-e7c4-27a8a06f6a26"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|class|                text|length|label|          token_text|          stop_token|           count_vec|              tf_idf|            features|\n",
            "+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|  ham|Go until jurong p...|   111|  0.0|[go, until, juron...|[go, jurong, poin...|(13423,[7,11,31,6...|(13423,[7,11,31,6...|(13424,[7,11,31,6...|\n",
            "|  ham|Ok lar... Joking ...|    29|  0.0|[ok, lar..., joki...|[ok, lar..., joki...|(13423,[0,24,301,...|(13423,[0,24,301,...|(13424,[0,24,301,...|\n",
            "| spam|Free entry in 2 a...|   155|  1.0|[free, entry, in,...|[free, entry, 2, ...|(13423,[2,13,19,3...|(13423,[2,13,19,3...|(13424,[2,13,19,3...|\n",
            "|  ham|U dun say so earl...|    49|  0.0|[u, dun, say, so,...|[u, dun, say, ear...|(13423,[0,70,80,1...|(13423,[0,70,80,1...|(13424,[0,70,80,1...|\n",
            "|  ham|Nah I don't think...|    61|  0.0|[nah, i, don't, t...|[nah, think, goes...|(13423,[36,134,31...|(13423,[36,134,31...|(13424,[36,134,31...|\n",
            "| spam|FreeMsg Hey there...|   147|  1.0|[freemsg, hey, th...|[freemsg, hey, da...|(13423,[10,60,140...|(13423,[10,60,140...|(13424,[10,60,140...|\n",
            "|  ham|Even my brother i...|    77|  0.0|[even, my, brothe...|[even, brother, l...|(13423,[10,53,102...|(13423,[10,53,102...|(13424,[10,53,102...|\n",
            "|  ham|As per your reque...|   160|  0.0|[as, per, your, r...|[per, request, 'm...|(13423,[127,185,4...|(13423,[127,185,4...|(13424,[127,185,4...|\n",
            "| spam|WINNER!! As a val...|   157|  1.0|[winner!!, as, a,...|[winner!!, valued...|(13423,[1,47,121,...|(13423,[1,47,121,...|(13424,[1,47,121,...|\n",
            "| spam|Had your mobile 1...|   154|  1.0|[had, your, mobil...|[mobile, 11, mont...|(13423,[0,1,13,27...|(13423,[0,1,13,27...|(13424,[0,1,13,27...|\n",
            "|  ham|I'm gonna be home...|   109|  0.0|[i'm, gonna, be, ...|[gonna, home, soo...|(13423,[18,43,117...|(13423,[18,43,117...|(13424,[18,43,117...|\n",
            "| spam|SIX chances to wi...|   136|  1.0|[six, chances, to...|[six, chances, wi...|(13423,[8,16,37,8...|(13423,[8,16,37,8...|(13424,[8,16,37,8...|\n",
            "| spam|URGENT! You have ...|   155|  1.0|[urgent!, you, ha...|[urgent!, won, 1,...|(13423,[13,30,47,...|(13423,[13,30,47,...|(13424,[13,30,47,...|\n",
            "|  ham|I've been searchi...|   196|  0.0|[i've, been, sear...|[searching, right...|(13423,[39,95,221...|(13423,[39,95,221...|(13424,[39,95,221...|\n",
            "|  ham|I HAVE A DATE ON ...|    35|  0.0|[i, have, a, date...|[date, sunday, wi...|(13423,[555,1797,...|(13423,[555,1797,...|(13424,[555,1797,...|\n",
            "| spam|XXXMobileMovieClu...|   149|  1.0|[xxxmobilemoviecl...|[xxxmobilemoviecl...|(13423,[30,109,11...|(13423,[30,109,11...|(13424,[30,109,11...|\n",
            "|  ham|Oh k...i'm watchi...|    26|  0.0|[oh, k...i'm, wat...|[oh, k...i'm, wat...|(13423,[82,214,44...|(13423,[82,214,44...|(13424,[82,214,44...|\n",
            "|  ham|Eh u remember how...|    81|  0.0|[eh, u, remember,...|[eh, u, remember,...|(13423,[0,2,49,13...|(13423,[0,2,49,13...|(13424,[0,2,49,13...|\n",
            "|  ham|Fine if thats th...|    56|  0.0|[fine, if, thats...|[fine, thats, wa...|(13423,[0,74,105,...|(13423,[0,74,105,...|(13424,[0,74,105,...|\n",
            "| spam|England v Macedon...|   155|  1.0|[england, v, mace...|[england, v, mace...|(13423,[4,30,33,5...|(13423,[4,30,33,5...|(13424,[4,30,33,5...|\n",
            "+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show columns\n",
        "clean_data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_9sRiLdOEv0",
        "outputId": "662acdc7-1e5f-4b77-8db0-15c6f5ad1f6b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function JavaWrapper.__del__ at 0x7f61ffcb6200>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyspark/ml/wrapper.py\", line 53, in __del__\n",
            "    if SparkContext._active_spark_context and self._java_obj is not None:\n",
            "AttributeError: 'VectorAssembler' object has no attribute '_java_obj'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['class',\n",
              " 'text',\n",
              " 'length',\n",
              " 'label',\n",
              " 'token_text',\n",
              " 'stop_token',\n",
              " 'count_vec',\n",
              " 'tf_idf',\n",
              " 'features']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a final_data DataFrame\n",
        "final_data = clean_data.select('label', 'features')"
      ],
      "metadata": {
        "id": "Wu2vMo4rOHAG"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show data\n",
        "final_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PK-wK0sIOwBH",
        "outputId": "d7352e30-606f-49d9-b613-a3e6e4260792"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|  0.0|(13424,[7,11,31,6...|\n",
            "|  0.0|(13424,[0,24,301,...|\n",
            "|  1.0|(13424,[2,13,19,3...|\n",
            "|  0.0|(13424,[0,70,80,1...|\n",
            "|  0.0|(13424,[36,134,31...|\n",
            "|  1.0|(13424,[10,60,140...|\n",
            "|  0.0|(13424,[10,53,102...|\n",
            "|  0.0|(13424,[127,185,4...|\n",
            "|  1.0|(13424,[1,47,121,...|\n",
            "|  1.0|(13424,[0,1,13,27...|\n",
            "|  0.0|(13424,[18,43,117...|\n",
            "|  1.0|(13424,[8,16,37,8...|\n",
            "|  1.0|(13424,[13,30,47,...|\n",
            "|  0.0|(13424,[39,95,221...|\n",
            "|  0.0|(13424,[555,1797,...|\n",
            "|  1.0|(13424,[30,109,11...|\n",
            "|  0.0|(13424,[82,214,44...|\n",
            "|  0.0|(13424,[0,2,49,13...|\n",
            "|  0.0|(13424,[0,74,105,...|\n",
            "|  1.0|(13424,[4,30,33,5...|\n",
            "+-----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and evaluate the model"
      ],
      "metadata": {
        "id": "YLboZa_HOwxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into train and test\n",
        "train_data, test_data = clean_data.randomSplit([0.7, 0.3])"
      ],
      "metadata": {
        "id": "9zUWC-KEPLwm"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Declare the ML method we'll use to solve the problem. In this case, the Naive Bayes\n",
        "nb = NaiveBayes()"
      ],
      "metadata": {
        "id": "Zt-dwRhWLyia"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model with our train_data\n",
        "spam_detector = nb.fit(train_data)"
      ],
      "metadata": {
        "id": "urPP3FC6Pgsf"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with our test_data\n",
        "test_results = spam_detector.transform(test_data)"
      ],
      "metadata": {
        "id": "o_VVhQgwPoQO"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show results\n",
        "test_results.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCBEKb1JP15E",
        "outputId": "e9651cdb-7eac-4ec6-91bb-36fe5c6ecd00"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|class|                text|length|label|          token_text|          stop_token|           count_vec|              tf_idf|            features|       rawPrediction|         probability|prediction|\n",
            "+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|  ham| &lt;#&gt;  mins ...|    51|  0.0|[, &lt;#&gt;, , m...|[, &lt;#&gt;, , m...|(13423,[3,6,41,20...|(13423,[3,6,41,20...|(13424,[3,6,41,20...|[-296.04288785039...|[1.0,1.5372845189...|       0.0|\n",
            "|  ham| &lt;DECIMAL&gt; ...|   132|  0.0|[, &lt;decimal&gt...|[, &lt;decimal&gt...|(13423,[3,84,115,...|(13423,[3,84,115,...|(13424,[3,84,115,...|[-880.43960646866...|[1.0,7.6178288312...|       0.0|\n",
            "|  ham| and  picking the...|    41|  0.0|[, and, , picking...|[, , picking, var...|(13423,[3,723,200...|(13423,[3,723,200...|(13424,[3,723,200...|[-261.75701997505...|[1.0,1.1817358461...|       0.0|\n",
            "|  ham| came to look at ...|   103|  0.0|[, came, to, look...|[, came, look, fl...|(13423,[3,11,163,...|(13423,[3,11,163,...|(13424,[3,11,163,...|[-1039.6622579176...|[1.0,3.3660567424...|       0.0|\n",
            "|  ham| gonna let me kno...|    95|  0.0|[, gonna, let, me...|[, gonna, let, kn...|(13423,[3,12,78,8...|(13423,[3,12,78,8...|(13424,[3,12,78,8...|[-663.38859201679...|[1.0,2.1195181795...|       0.0|\n",
            "|  ham|\"Its Ur luck to L...|   155|  0.0|[\"its, ur, luck, ...|[\"its, ur, luck, ...|(13423,[4,21,29,1...|(13423,[4,21,29,1...|(13424,[4,21,29,1...|[-1216.2965539729...|[1.0,1.0038959523...|       0.0|\n",
            "|  ham|\"Life is nothing ...|   159|  0.0|[\"life, is, nothi...|[\"life, nothing, ...|(13423,[5,79,112,...|(13423,[5,79,112,...|(13424,[5,79,112,...|[-1379.8077282058...|[1.0,1.0106242097...|       0.0|\n",
            "|  ham|\"SYMPTOMS\" when U...|   139|  0.0|[\"symptoms\", when...|[\"symptoms\", u, l...|(13423,[0,5,10,32...|(13423,[0,5,10,32...|(13424,[0,5,10,32...|[-1092.3704847822...|[0.99999999999999...|       0.0|\n",
            "|  ham|\"Wen u miss someo...|   143|  0.0|[\"wen, u, miss, s...|[\"wen, u, miss, s...|(13423,[0,79,225,...|(13423,[0,79,225,...|(13424,[0,79,225,...|[-1069.5010341119...|[0.47076624774638...|       1.0|\n",
            "|  ham|&lt;#&gt;  is fas...|   461|  0.0|[&lt;#&gt;, , is,...|[&lt;#&gt;, , fas...|(13423,[0,3,6,8,1...|(13423,[0,3,6,8,1...|(13424,[0,3,6,8,1...|[-3637.8595167754...|[1.0,2.9925741685...|       0.0|\n",
            "|  ham|&lt;#&gt; %of ppl...|   327|  0.0|[&lt;#&gt;, %of, ...|[&lt;#&gt;, %of, ...|(13423,[0,2,3,5,6...|(13423,[0,2,3,5,6...|(13424,[0,2,3,5,6...|[-2555.7798137456...|[1.0,6.9084129979...|       0.0|\n",
            "|  ham|(And my man carlo...|    66|  0.0|[(and, my, man, c...|[(and, man, carlo...|(13423,[163,242,6...|(13423,[163,242,6...|(13424,[163,242,6...|[-580.40350326671...|[1.0,2.0131877366...|       0.0|\n",
            "|  ham|(I should add tha...|   132|  0.0|[(i, should, add,...|[(i, add, really,...|(13423,[5,18,72,1...|(13423,[5,18,72,1...|(13424,[5,18,72,1...|[-706.22029863099...|[1.0,1.6134257011...|       0.0|\n",
            "|  ham|(That said can yo...|    43|  0.0|[(that, said, can...|[(that, said, tex...|(13423,[19,29,92,...|(13423,[19,29,92,...|(13424,[19,29,92,...|[-318.35626926021...|[0.99892417714300...|       0.0|\n",
            "|  ham|(You didn't hear ...|    28|  0.0|[(you, didn't, he...|   [(you, hear, me)]|(13423,[264,6027,...|(13423,[264,6027,...|(13424,[264,6027,...|[-265.38156155224...|[2.00249937381926...|       1.0|\n",
            "|  ham|1 in cbe. 2 in ch...|    23|  0.0|[1, in, cbe., 2, ...|[1, cbe., 2, chen...|(13423,[2,100,972...|(13423,[2,100,972...|(13424,[2,100,972...|[-272.76979301836...|[3.66846232778075...|       1.0|\n",
            "|  ham|1's reach home ca...|    23|  0.0|[1's, reach, home...|[1's, reach, home...|(13423,[1,43,53,2...|(13423,[1,43,53,2...|(13424,[1,43,53,2...|[-212.90580390486...|[0.99999999999564...|       0.0|\n",
            "|  ham|1) Go to write ms...|   141|  0.0|[1), go, to, writ...|[1), go, write, m...|(13423,[3,4,6,7,9...|(13423,[3,4,6,7,9...|(13424,[3,4,6,7,9...|[-1175.6479229936...|[1.0,1.4831829275...|       0.0|\n",
            "|  ham|1.20 that call co...|    79|  0.0|[1.20, that, call...|[1.20, call, cost...|(13423,[1,18,21,2...|(13423,[1,18,21,2...|(13424,[1,18,21,2...|[-784.49533143890...|[1.0,3.2457065827...|       0.0|\n",
            "|  ham|   10 min later k...|    17|  0.0|[10, min, later, ...|[10, min, later, ...|(13423,[56,356,62...|(13423,[56,356,62...|(13424,[56,356,62...|[-214.47561594877...|[0.99999999995833...|       0.0|\n",
            "+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create evaluator object\n",
        "acc_eval = MulticlassClassificationEvaluator()"
      ],
      "metadata": {
        "id": "IOjynbzfP3wK"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "acc = acc_eval.evaluate(test_results)"
      ],
      "metadata": {
        "id": "ijfaadHGQGu3"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the results\n",
        "print(f'ACC of NB Model: {acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0S8QGJyQLS7",
        "outputId": "fb79ee86-a96a-4851-a5a0-1cf38053a49e"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACC of NB Model: 0.9144625934257442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nothing bad! We have a model with a 91% accuracy!\n",
        "\n",
        "This predicts whether a text is a spam message or not with a high acc"
      ],
      "metadata": {
        "id": "iQoqbBc9QQ3y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7XxdA3hBRs_o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}