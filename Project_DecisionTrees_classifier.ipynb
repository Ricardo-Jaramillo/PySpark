{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ricardo-Jaramillo/PySpark/blob/main/Project_DecisionTrees_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5CnIeDDZfmR"
      },
      "source": [
        "# Tree Methods Consulting Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fajtpd82ZfmT"
      },
      "source": [
        "You've been hired by a dog food company to try to predict why some batches of their dog food are spoiling much quicker than intended! Unfortunately this Dog Food company hasn't upgraded to the latest machinery, meaning that the amounts of the five preservative chemicals they are using can vary a lot, but which is the chemical that has the strongest effect? The dog food company first mixes up a batch of preservative that contains 4 different preservative chemicals (A,B,C,D) and then is completed with a \"filler\" chemical. The food scientists beelive one of the A,B,C, or D preservatives is causing the problem, but need your help to figure out which one!\n",
        "Use Machine Learning with RF to find out which parameter had the most predicitive power, thus finding out which chemical causes the early spoiling! So create a model and then find out how you can decide which chemical is the problem!\n",
        "\n",
        "* Pres_A : Percentage of preservative A in the mix\n",
        "* Pres_B : Percentage of preservative B in the mix\n",
        "* Pres_C : Percentage of preservative C in the mix\n",
        "* Pres_D : Percentage of preservative D in the mix\n",
        "* Spoiled: Label indicating whether or not the dog food batch was spoiled.\n",
        "___\n",
        "\n",
        "**Think carefully about what this problem is really asking you to solve. While we will use Machine Learning to solve this, it won't be with your typical train/test split workflow. If this confuses you, skip ahead to the solution code along walk-through!**\n",
        "____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBbrQ7KkZfmV"
      },
      "source": [
        "# Good Luck!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install pyspark and download the data"
      ],
      "metadata": {
        "id": "g4tmU1n8ER_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install pyspark\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-l0R-ryAxWF",
        "outputId": "35022034-f963-499f-99e6-9d96c047af15"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=3edd88764f33997748975b24da2c7cb96ce52d782ba1a9854ffe5cc5a8ad9b34\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the necessary files\n",
        "!wget https://raw.githubusercontent.com/Ricardo-Jaramillo/PySpark/main/datasets/DecisionTress/dog_food.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp-Ah7s7A1zO",
        "outputId": "453b18f5-a8a3-4f14-bf7d-292e810683b0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-04 15:59:25--  https://raw.githubusercontent.com/Ricardo-Jaramillo/PySpark/main/datasets/DecisionTress/dog_food.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7197 (7.0K) [text/plain]\n",
            "Saving to: ‘dog_food.csv’\n",
            "\n",
            "\rdog_food.csv          0%[                    ]       0  --.-KB/s               \rdog_food.csv        100%[===================>]   7.03K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-04 15:59:25 (102 MB/s) - ‘dog_food.csv’ saved [7197/7197]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries and read in the data"
      ],
      "metadata": {
        "id": "xF-cP1A4EXpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier, GBTClassifier, DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.feature import StringIndexer"
      ],
      "metadata": {
        "id": "Zb9JMk8SA77c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a spark session\n",
        "spark = SparkSession.builder.appName('dog_food_project').getOrCreate()"
      ],
      "metadata": {
        "id": "WUOtZfokBH03"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in the data\n",
        "data = spark.read.csv('dog_food.csv', header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "F1ByIPyfEBCW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Schema\n",
        "data.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1oVG8kzI3KF",
        "outputId": "3cde5248-5324-46dd-dbc8-96b238802aca"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- A: integer (nullable = true)\n",
            " |-- B: integer (nullable = true)\n",
            " |-- C: double (nullable = true)\n",
            " |-- D: integer (nullable = true)\n",
            " |-- Spoiled: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the data\n",
        "data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZlWN4aXEIj0",
        "outputId": "6819cabd-7d10-4d97-b989-b9c4a5de39aa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+---+-------+\n",
            "|  A|  B|   C|  D|Spoiled|\n",
            "+---+---+----+---+-------+\n",
            "|  4|  2|12.0|  3|    1.0|\n",
            "|  5|  6|12.0|  7|    1.0|\n",
            "|  6|  2|13.0|  6|    1.0|\n",
            "|  4|  2|12.0|  1|    1.0|\n",
            "|  4|  2|12.0|  3|    1.0|\n",
            "| 10|  3|13.0|  9|    1.0|\n",
            "|  8|  5|14.0|  5|    1.0|\n",
            "|  5|  8|12.0|  8|    1.0|\n",
            "|  6|  5|12.0|  9|    1.0|\n",
            "|  3|  3|12.0|  1|    1.0|\n",
            "|  9|  8|11.0|  3|    1.0|\n",
            "|  1| 10|12.0|  3|    1.0|\n",
            "|  1|  5|13.0| 10|    1.0|\n",
            "|  2| 10|12.0|  6|    1.0|\n",
            "|  1| 10|11.0|  4|    1.0|\n",
            "|  5|  3|12.0|  2|    1.0|\n",
            "|  4|  9|11.0|  8|    1.0|\n",
            "|  5|  1|11.0|  1|    1.0|\n",
            "|  4|  9|12.0| 10|    1.0|\n",
            "|  5|  8|10.0|  9|    1.0|\n",
            "+---+---+----+---+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assemble data into a features columns\n",
        "We'll need to index the lable `Private` with the StringIndexer method"
      ],
      "metadata": {
        "id": "_wkfdFR_UEjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out columns\n",
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Us4kA2_Zd7B6",
        "outputId": "5c558249-8f21-432b-850e-b29d2111159f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A', 'B', 'C', 'D', 'Spoiled']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create object assembler\n",
        "assembler = VectorAssembler(inputCols=['A', 'B', 'C', 'D'],\n",
        "                            outputCol='features')"
      ],
      "metadata": {
        "id": "4TUK2KqPdzmJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create features column from assembler\n",
        "output = assembler.transform(data)\n",
        "output.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tKlJ63zeDM_",
        "outputId": "ba73d914-1350-4779-adf2-ad9c4084e7a8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+---+-------+-------------------+\n",
            "|  A|  B|   C|  D|Spoiled|           features|\n",
            "+---+---+----+---+-------+-------------------+\n",
            "|  4|  2|12.0|  3|    1.0| [4.0,2.0,12.0,3.0]|\n",
            "|  5|  6|12.0|  7|    1.0| [5.0,6.0,12.0,7.0]|\n",
            "|  6|  2|13.0|  6|    1.0| [6.0,2.0,13.0,6.0]|\n",
            "|  4|  2|12.0|  1|    1.0| [4.0,2.0,12.0,1.0]|\n",
            "|  4|  2|12.0|  3|    1.0| [4.0,2.0,12.0,3.0]|\n",
            "| 10|  3|13.0|  9|    1.0|[10.0,3.0,13.0,9.0]|\n",
            "|  8|  5|14.0|  5|    1.0| [8.0,5.0,14.0,5.0]|\n",
            "|  5|  8|12.0|  8|    1.0| [5.0,8.0,12.0,8.0]|\n",
            "|  6|  5|12.0|  9|    1.0| [6.0,5.0,12.0,9.0]|\n",
            "|  3|  3|12.0|  1|    1.0| [3.0,3.0,12.0,1.0]|\n",
            "|  9|  8|11.0|  3|    1.0| [9.0,8.0,11.0,3.0]|\n",
            "|  1| 10|12.0|  3|    1.0|[1.0,10.0,12.0,3.0]|\n",
            "|  1|  5|13.0| 10|    1.0|[1.0,5.0,13.0,10.0]|\n",
            "|  2| 10|12.0|  6|    1.0|[2.0,10.0,12.0,6.0]|\n",
            "|  1| 10|11.0|  4|    1.0|[1.0,10.0,11.0,4.0]|\n",
            "|  5|  3|12.0|  2|    1.0| [5.0,3.0,12.0,2.0]|\n",
            "|  4|  9|11.0|  8|    1.0| [4.0,9.0,11.0,8.0]|\n",
            "|  5|  1|11.0|  1|    1.0| [5.0,1.0,11.0,1.0]|\n",
            "|  4|  9|12.0| 10|    1.0|[4.0,9.0,12.0,10.0]|\n",
            "|  5|  8|10.0|  9|    1.0| [5.0,8.0,10.0,9.0]|\n",
            "+---+---+----+---+-------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select only the features and labels\n",
        "final_data = output.select('Spoiled', 'features')\n",
        "final_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_F8WCwBue1XN",
        "outputId": "0e91c512-3875-4445-ad49-9f99d0e58c14"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------------+\n",
            "|Spoiled|           features|\n",
            "+-------+-------------------+\n",
            "|    1.0| [4.0,2.0,12.0,3.0]|\n",
            "|    1.0| [5.0,6.0,12.0,7.0]|\n",
            "|    1.0| [6.0,2.0,13.0,6.0]|\n",
            "|    1.0| [4.0,2.0,12.0,1.0]|\n",
            "|    1.0| [4.0,2.0,12.0,3.0]|\n",
            "|    1.0|[10.0,3.0,13.0,9.0]|\n",
            "|    1.0| [8.0,5.0,14.0,5.0]|\n",
            "|    1.0| [5.0,8.0,12.0,8.0]|\n",
            "|    1.0| [6.0,5.0,12.0,9.0]|\n",
            "|    1.0| [3.0,3.0,12.0,1.0]|\n",
            "|    1.0| [9.0,8.0,11.0,3.0]|\n",
            "|    1.0|[1.0,10.0,12.0,3.0]|\n",
            "|    1.0|[1.0,5.0,13.0,10.0]|\n",
            "|    1.0|[2.0,10.0,12.0,6.0]|\n",
            "|    1.0|[1.0,10.0,11.0,4.0]|\n",
            "|    1.0| [5.0,3.0,12.0,2.0]|\n",
            "|    1.0| [4.0,9.0,11.0,8.0]|\n",
            "|    1.0| [5.0,1.0,11.0,1.0]|\n",
            "|    1.0|[4.0,9.0,12.0,10.0]|\n",
            "|    1.0| [5.0,8.0,10.0,9.0]|\n",
            "+-------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **NOTE:** Since the problem only requires to find the most weighted variable in the model (which preservative influences the most to the result of spoiled or not), we don't need to split the data into train and test. We're not trying to predict whether a row is poiled or not."
      ],
      "metadata": {
        "id": "aZ0_947ueMNg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Fit Decision Tree models"
      ],
      "metadata": {
        "id": "vC-PmhfQVx-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create classifier objects\n",
        "dtc = DecisionTreeClassifier(labelCol='Spoiled', featuresCol='features')\n",
        "rfc = RandomForestClassifier(labelCol='Spoiled', featuresCol='features')\n",
        "gbt = GBTClassifier(labelCol='Spoiled', featuresCol='features')"
      ],
      "metadata": {
        "id": "YafUoVD1WJvi"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit models\n",
        "dtc_model = dtc.fit(final_data)\n",
        "rfc_model = rfc.fit(final_data)\n",
        "gbt_model = gbt.fit(final_data)"
      ],
      "metadata": {
        "id": "8WHwrdcxWZZs"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now check the 'featureImportance of the train models\n",
        "print(f'DTC feature importances: {dtc_model.featureImportances}')\n",
        "print(f'RFC feature importances: {rfc_model.featureImportances}')\n",
        "print(f'GBT feature importances: {gbt_model.featureImportances}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuqJ2bgRfJ7K",
        "outputId": "cf97ae5e-a24d-4b68-c169-d0ba81d2e6c6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DTC feature importances: (4,[1,2,3],[0.0019107795086908742,0.9831676511855764,0.014921569305732818])\n",
            "RFC feature importances: (4,[0,1,2,3],[0.015496512702336391,0.025991843685610527,0.9392441723914908,0.019267471220562302])\n",
            "GBT feature importances: (4,[0,1,2,3],[0.02962567485294246,0.03830179415146122,0.8286277188140007,0.10344481218159562])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "The feature importances of each model shows the 3rd parameter with the greatest value, this indicates that the C preservative influences the most on the result of a spoiled dog food.\n",
        "\n",
        "**C is the answer**"
      ],
      "metadata": {
        "id": "fPUAwPFkfQT-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wVi5EUT4gRIs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [conda root]",
      "language": "python",
      "name": "conda-root-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}