{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ricardo-Jaramillo/PySpark/blob/main/Spark_DataFrames_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2q9xEvRzF3LF"
      },
      "source": [
        "# Spark DataFrames Project Exercise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbXXj0j3F3LH"
      },
      "source": [
        "Let's get some quick practice with Spark DataFrame skills.\n",
        "\n",
        "You're going to resolve some basic questions about some stock market data, in this case Walmart Stock from the years 2012-2017.\n",
        "\n",
        "This exercise will just ask a bunch of questions, unlike the future machine learning exercises, which will be a little looser and be in the form of \"Consulting Projects\".\n",
        "\n",
        "Complete the tasks below.\n",
        "\n",
        "This project comes from the Jose Portilla's course on Spark and PySpark."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbgmWnn-F3LI"
      },
      "source": [
        "#### Use the walmart_stock.csv file to Answer and complete the  tasks below!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install pyspark\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ut_5KrCGUyv",
        "outputId": "7c978dce-c702-4883-a992-9455e812d825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=af48a6628f1916aa8ad35895b04d846fa2ffb952939078963ecf862ba4bf93c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the data\n",
        "!wget https://raw.githubusercontent.com/Ricardo-Jaramillo/PySpark/main/datasets/walmart_stock.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fwxlwzNGnd0",
        "outputId": "260b9cd6-c59d-4e43-917a-24ebddf8eb9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-03 01:15:41--  https://raw.githubusercontent.com/Ricardo-Jaramillo/PySpark/main/datasets/walmart_stock.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90266 (88K) [text/plain]\n",
            "Saving to: ‘walmart_stock.csv’\n",
            "\n",
            "\rwalmart_stock.csv     0%[                    ]       0  --.-KB/s               \rwalmart_stock.csv   100%[===================>]  88.15K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-10-03 01:15:42 (3.30 MB/s) - ‘walmart_stock.csv’ saved [90266/90266]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GucMv5sIF3LI"
      },
      "source": [
        "#### Start a simple Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vbgq7TWYF3LI"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('project').getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5InGmkxQF3LJ"
      },
      "source": [
        "#### Load the Walmart Stock CSV File, have Spark infer the data types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GAX4VMmJF3LJ"
      },
      "outputs": [],
      "source": [
        "# Read in the data file\n",
        "df = spark.read.csv('walmart_stock.csv', header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPqJdZ9MHV-S",
        "outputId": "e91041bd-4bcb-4678-965f-a1ebb8411e81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
            "|      Date|              Open|              High|               Low|             Close|  Volume|         Adj Close|\n",
            "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
            "|2012-01-03|         59.970001|         61.060001|         59.869999|         60.330002|12668800|52.619234999999996|\n",
            "|2012-01-04|60.209998999999996|         60.349998|         59.470001|59.709998999999996| 9593300|         52.078475|\n",
            "|2012-01-05|         59.349998|         59.619999|         58.369999|         59.419998|12768200|         51.825539|\n",
            "|2012-01-06|         59.419998|         59.450001|         58.869999|              59.0| 8069400|          51.45922|\n",
            "|2012-01-09|         59.029999|         59.549999|         58.919998|             59.18| 6679300|51.616215000000004|\n",
            "|2012-01-10|             59.43|59.709998999999996|             58.98|59.040001000000004| 6907300|         51.494109|\n",
            "|2012-01-11|         59.060001|         59.529999|59.040001000000004|         59.400002| 6365600|         51.808098|\n",
            "|2012-01-12|59.790001000000004|              60.0|         59.400002|              59.5| 7236400|51.895315999999994|\n",
            "|2012-01-13|             59.18|59.610001000000004|59.009997999999996|59.540001000000004| 7729300|51.930203999999996|\n",
            "|2012-01-17|         59.869999|60.110001000000004|             59.52|         59.849998| 8500000|         52.200581|\n",
            "|2012-01-18|59.790001000000004|         60.029999|         59.650002|60.009997999999996| 5911400|         52.340131|\n",
            "|2012-01-19|             59.93|             60.73|             59.75|60.610001000000004| 9234600|         52.863447|\n",
            "|2012-01-20|             60.75|             61.25|         60.669998|61.009997999999996|10378800|53.212320999999996|\n",
            "|2012-01-23|         60.810001|             60.98|60.509997999999996|             60.91| 7134100|         53.125104|\n",
            "|2012-01-24|             60.75|              62.0|             60.75|61.389998999999996| 7362800| 53.54375400000001|\n",
            "|2012-01-25|             61.18|61.610001000000004|61.040001000000004|         61.470001| 5915800| 53.61353100000001|\n",
            "|2012-01-26|         61.799999|             61.84|             60.77|         60.970001| 7436200|         53.177436|\n",
            "|2012-01-27|60.860001000000004|         61.119999|60.540001000000004|60.709998999999996| 6287300|         52.950665|\n",
            "|2012-01-30|         60.470001|             61.32|         60.349998|         61.299999| 7636900|53.465256999999994|\n",
            "|2012-01-31|         61.529999|             61.57|         60.580002|61.360001000000004| 9761500|53.517590000000006|\n",
            "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-yEXm5WF3LJ"
      },
      "source": [
        "#### What are the column names?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAHg3tQfHZAz",
        "outputId": "86d35a3d-ede1-4358-8929-c2b51e251703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNaCD9PUF3LK"
      },
      "source": [
        "#### What does the Schema look like?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnJL_hb1F3LK",
        "outputId": "cb19e5c0-b241-4256-c1b3-c2006e401849"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Date: date (nullable = true)\n",
            " |-- Open: double (nullable = true)\n",
            " |-- High: double (nullable = true)\n",
            " |-- Low: double (nullable = true)\n",
            " |-- Close: double (nullable = true)\n",
            " |-- Volume: integer (nullable = true)\n",
            " |-- Adj Close: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idQIkAdrF3LK"
      },
      "source": [
        "#### Print out the first 5 rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBoEJ16MF3LK",
        "outputId": "05f86943-b1d4-4c56-b5dd-cd49fa4ce838"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------+---------+---------+------------------+--------+------------------+\n",
            "|      Date|              Open|     High|      Low|             Close|  Volume|         Adj Close|\n",
            "+----------+------------------+---------+---------+------------------+--------+------------------+\n",
            "|2012-01-03|         59.970001|61.060001|59.869999|         60.330002|12668800|52.619234999999996|\n",
            "|2012-01-04|60.209998999999996|60.349998|59.470001|59.709998999999996| 9593300|         52.078475|\n",
            "|2012-01-05|         59.349998|59.619999|58.369999|         59.419998|12768200|         51.825539|\n",
            "|2012-01-06|         59.419998|59.450001|58.869999|              59.0| 8069400|          51.45922|\n",
            "|2012-01-09|         59.029999|59.549999|58.919998|             59.18| 6679300|51.616215000000004|\n",
            "+----------+------------------+---------+---------+------------------+--------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeLSNayRF3LL"
      },
      "source": [
        "#### Use describe() to learn about the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjpaI-pVF3LL",
        "outputId": "7d62e6a0-3873-45e1-bdf5-508fc27f51da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "|summary|              Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
            "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "|  count|              1258|             1258|             1258|             1258|             1258|             1258|\n",
            "|   mean| 72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n",
            "| stddev|  6.76809024470826|6.768186808159218|6.744075756255496|6.756859163732991|  4519780.8431556|6.722609449996857|\n",
            "|    min|56.389998999999996|        57.060001|        56.299999|        56.419998|          2094900|        50.363689|\n",
            "|    max|         90.800003|        90.970001|            89.25|        90.470001|         80898100|84.91421600000001|\n",
            "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.describe().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RtDd8fTF3LL"
      },
      "source": [
        "## Bonus Question!\n",
        "#### There are too many decimal places for mean and stddev in the describe() dataframe. Format the numbers to just show up to two decimal places. Pay careful attention to the datatypes that .describe() returns, we didn't cover how to do this exact formatting, but we covered something very similar. [Check this link for a hint](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.Column.cast)\n",
        "\n",
        "If you get stuck on this, don't worry, just view the solutions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "E8i3ASXnF3LL",
        "outputId": "783b0003-5b17-4aac-fbc3-3005b0311006",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- summary: string (nullable = true)\n",
            " |-- Open: string (nullable = true)\n",
            " |-- High: string (nullable = true)\n",
            " |-- Low: string (nullable = true)\n",
            " |-- Close: string (nullable = true)\n",
            " |-- Volume: string (nullable = true)\n",
            " |-- Adj Close: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.describe().printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "collapsed": true,
        "id": "Dp1RR_J9F3LL"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import format_number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "yehNLPIDF3LL",
        "outputId": "f5f443fb-a401-43ae-e5f1-92ab5c64e71d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+--------+--------+--------+--------+\n",
            "|summary|    Open|    High|     Low|   Close|  Volume|\n",
            "+-------+--------+--------+--------+--------+--------+\n",
            "|  count|1,258.00|1,258.00|1,258.00|1,258.00|    1258|\n",
            "|   mean|   72.36|   72.84|   71.92|   72.39| 8222093|\n",
            "| stddev|    6.77|    6.77|    6.74|    6.76| 4519780|\n",
            "|    min|   56.39|   57.06|   56.30|   56.42| 2094900|\n",
            "|    max|   90.80|   90.97|   89.25|   90.47|80898100|\n",
            "+-------+--------+--------+--------+--------+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result = df.describe()\n",
        "result.select(result['summary'],\n",
        "              format_number(result['Open'].cast('float'),2).alias('Open'),\n",
        "              format_number(result['High'].cast('float'),2).alias('High'),\n",
        "              format_number(result['Low'].cast('float'),2).alias('Low'),\n",
        "              format_number(result['Close'].cast('float'),2).alias('Close'),\n",
        "              result['Volume'].cast('int').alias('Volume')\n",
        "             ).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2U8cTPS4F3LL"
      },
      "source": [
        "#### Create a new dataframe with a column called HV Ratio that is the ratio of the High Price versus volume of stock traded for a day."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ahg7ogM-F3LL",
        "outputId": "ae3e8e5a-5a5f-4b06-9267-785affaafc36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|            HV Ratio|\n",
            "+--------------------+\n",
            "|4.819714653321546E-6|\n",
            "|6.290848613094555E-6|\n",
            "|4.669412994783916E-6|\n",
            "|7.367338463826307E-6|\n",
            "|8.915604778943901E-6|\n",
            "|8.644477436914568E-6|\n",
            "|9.351828421515645E-6|\n",
            "| 8.29141562102703E-6|\n",
            "|7.712212102001476E-6|\n",
            "|7.071764823529412E-6|\n",
            "|1.015495466386981E-5|\n",
            "|6.576354146362592...|\n",
            "| 5.90145296180676E-6|\n",
            "|8.547679455011844E-6|\n",
            "|8.420709512685392E-6|\n",
            "|1.041448341728929...|\n",
            "|8.316075414862431E-6|\n",
            "|9.721183814992126E-6|\n",
            "|8.029436027707578E-6|\n",
            "|6.307432259386365E-6|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.withColumn('HV Ratio', df['High'] / df['Volume']).select('HV Ratio').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPL_9TENF3LM"
      },
      "source": [
        "#### What day had the Peak High in Price?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "X2kN7lJEF3LM",
        "outputId": "c35b5a20-cbdb-4413-95d5-44d83bc4622d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+---------+-----+---------+-------+---------+\n",
            "|      Date|     Open|     High|  Low|    Close| Volume|Adj Close|\n",
            "+----------+---------+---------+-----+---------+-------+---------+\n",
            "|2015-01-13|90.800003|90.970001|88.93|89.309998|8215400|83.825448|\n",
            "+----------+---------+---------+-----+---------+-------+---------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.orderBy(df['High'].desc()).show(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CmfuVV4F3LM"
      },
      "source": [
        "#### What is the mean of the Close column?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "iN4mKDjIF3LM",
        "outputId": "fb64b9bc-f4e9-4ad6-d42b-f9d22e67e238",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+\n",
            "|       avg(Close)|\n",
            "+-----------------+\n",
            "|72.38844998012726|\n",
            "+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import mean\n",
        "df.select(mean('Close')).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX2MFXVFF3LM"
      },
      "source": [
        "#### What is the max and min of the Volume column?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "collapsed": true,
        "id": "Sbjf-7laF3LM"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import min, max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "DDTNIy51F3LM",
        "outputId": "c98787e3-95e7-436c-97ed-672866aa1b5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+\n",
            "|max(Volume)|min(Volume)|\n",
            "+-----------+-----------+\n",
            "|   80898100|    2094900|\n",
            "+-----------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.select(max('Volume'), min('Volume')).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wof3IhxF3LM"
      },
      "source": [
        "#### How many days was the Close lower than 60 dollars?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "tpPtkdlfF3LN",
        "outputId": "34907e29-c958-48c8-e909-cee7ccf81a88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "df.filter('Close < 60').count()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(df['Close'] < 60).count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdV3xISEMoIZ",
        "outputId": "ae88e683-e314-4241-ed0c-80c370f398a4"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RiMxM2tF3LN"
      },
      "source": [
        "#### What percentage of the time was the High greater than 80 dollars ?\n",
        "#### In other words, (Number of Days High>80)/(Total Days in the dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Pn8RQI8GF3LN",
        "outputId": "cbb92eac-2ce3-4555-c45e-6f69c18604d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.141494435612083"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "df.filter('High > 80').count() / df.count() * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f641W8seF3LN"
      },
      "source": [
        "#### What is the Pearson correlation between High and Volume?\n",
        "#### [Hint](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrameStatFunctions.corr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "fo_CtP-bF3LN",
        "outputId": "2273add4-04e6-4b1d-c4c1-6c839cde19ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+\n",
            "| corr(High, Volume)|\n",
            "+-------------------+\n",
            "|-0.3384326061737161|\n",
            "+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import corr\n",
        "df.select(corr('High', 'Volume')).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CD2Rg5eF3LN"
      },
      "source": [
        "#### What is the max High per year?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rd1kRhCNNf2",
        "outputId": "72ded92c-6858-44d2-e977-edbbbd7356cc"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
            "|      Date|              Open|              High|               Low|             Close|  Volume|         Adj Close|\n",
            "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
            "|2012-01-03|         59.970001|         61.060001|         59.869999|         60.330002|12668800|52.619234999999996|\n",
            "|2012-01-04|60.209998999999996|         60.349998|         59.470001|59.709998999999996| 9593300|         52.078475|\n",
            "|2012-01-05|         59.349998|         59.619999|         58.369999|         59.419998|12768200|         51.825539|\n",
            "|2012-01-06|         59.419998|         59.450001|         58.869999|              59.0| 8069400|          51.45922|\n",
            "|2012-01-09|         59.029999|         59.549999|         58.919998|             59.18| 6679300|51.616215000000004|\n",
            "|2012-01-10|             59.43|59.709998999999996|             58.98|59.040001000000004| 6907300|         51.494109|\n",
            "|2012-01-11|         59.060001|         59.529999|59.040001000000004|         59.400002| 6365600|         51.808098|\n",
            "|2012-01-12|59.790001000000004|              60.0|         59.400002|              59.5| 7236400|51.895315999999994|\n",
            "|2012-01-13|             59.18|59.610001000000004|59.009997999999996|59.540001000000004| 7729300|51.930203999999996|\n",
            "|2012-01-17|         59.869999|60.110001000000004|             59.52|         59.849998| 8500000|         52.200581|\n",
            "|2012-01-18|59.790001000000004|         60.029999|         59.650002|60.009997999999996| 5911400|         52.340131|\n",
            "|2012-01-19|             59.93|             60.73|             59.75|60.610001000000004| 9234600|         52.863447|\n",
            "|2012-01-20|             60.75|             61.25|         60.669998|61.009997999999996|10378800|53.212320999999996|\n",
            "|2012-01-23|         60.810001|             60.98|60.509997999999996|             60.91| 7134100|         53.125104|\n",
            "|2012-01-24|             60.75|              62.0|             60.75|61.389998999999996| 7362800| 53.54375400000001|\n",
            "|2012-01-25|             61.18|61.610001000000004|61.040001000000004|         61.470001| 5915800| 53.61353100000001|\n",
            "|2012-01-26|         61.799999|             61.84|             60.77|         60.970001| 7436200|         53.177436|\n",
            "|2012-01-27|60.860001000000004|         61.119999|60.540001000000004|60.709998999999996| 6287300|         52.950665|\n",
            "|2012-01-30|         60.470001|             61.32|         60.349998|         61.299999| 7636900|53.465256999999994|\n",
            "|2012-01-31|         61.529999|             61.57|         60.580002|61.360001000000004| 9761500|53.517590000000006|\n",
            "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import year\n",
        "df_by_year = df.withColumn('Year', year(df['Date'])).groupBy('Year').max()"
      ],
      "metadata": {
        "id": "McoLufphNPWK"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "t2WKiGn7F3LN",
        "outputId": "0b9423b8-0f77-4e63-f257-1868f00fbb4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---------+\n",
            "|Year|max(High)|\n",
            "+----+---------+\n",
            "|2015|90.970001|\n",
            "|2013|81.370003|\n",
            "|2014|88.089996|\n",
            "|2012|77.599998|\n",
            "|2016|75.190002|\n",
            "+----+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_by_year.select(['Year', 'max(High)']).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMnIXWCzF3LN"
      },
      "source": [
        "#### What is the average Close for each Calendar Month?\n",
        "#### In other words, across all the years, what is the average Close price for Jan,Feb, Mar, etc... Your result will have a value for each of these months."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "tCIDpd9fF3LN",
        "outputId": "7c3f9b6f-ab1a-4513-cebc-911b01bcbc6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------------+\n",
            "|Month|       avg(Close)|\n",
            "+-----+-----------------+\n",
            "|   12|72.84792478301885|\n",
            "|    1|71.44801958415842|\n",
            "|    6| 72.4953774245283|\n",
            "|    3|71.77794377570092|\n",
            "|    5|72.30971688679247|\n",
            "|    9|72.18411785294116|\n",
            "|    4|72.97361900952382|\n",
            "|    8|73.02981855454546|\n",
            "|    7|74.43971943925233|\n",
            "|   10|71.57854545454543|\n",
            "|   11| 72.1110893069307|\n",
            "|    2|  71.306804443299|\n",
            "+-----+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import month\n",
        "df_by_month = df.withColumn('Month', month(df['Date'])).groupBy('Month').avg()\n",
        "df_by_month.select(['Month', 'avg(Close)']).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qACs8grF3LO"
      },
      "source": [
        "# Great Job!"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [conda root]",
      "language": "python",
      "name": "conda-root-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
