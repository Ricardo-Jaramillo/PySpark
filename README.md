# PySpark

In this series of notebooks I'll follow the course of Jose Portilla and apply some of my own comments.
The course shows how to install and use PySpark in 4 different ways, a Virtual Machine Environment was sett as the main way.

Originally the course is taken with a linux OS in a VM env. I just moved onto Colab and here's my journey...

## Considerations

On each notebook it's necessary to instal pyspark through the command **!pip install pyspark** and import the necessary cvs files.
All documentation can be find on the official [Spark website](https://spark.apache.org/docs/latest/ml-guide.html)
