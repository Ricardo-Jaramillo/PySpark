{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7uWW5gRzgC6wPy2g0x4/J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ricardo-Jaramillo/PySpark/blob/main/13_NLP_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Natural Language Processing\n",
        "\n",
        "Examples of NLP\n",
        "* Clustering News Articles\n",
        "* Suggesting similar books\n",
        "* Grouping Legal Documents\n",
        "* Analysing Consumer Feedback\n",
        "* Spam Email Detection\n",
        "\n",
        "Basic process of NLP:\n",
        "* Compile all documents\n",
        "* Featurize the words to numbers\n",
        "* Compare features of documents\n",
        "\n",
        "A standard way to featurize word to numbers is though the use of **TF-IDF** methods.\n",
        "\n",
        "TF-IDF stands for *Term Frequency - Inverse Document Frequency*\n",
        "\n",
        "```\n",
        "𝐖ₓᵧ = 𝚝𝚏ₓᵧ * log(𝙽÷𝚍𝚏ₓ)\n",
        "  where:\n",
        "  𝚝𝚏ₓᵧ = frequency of x in y\n",
        "  𝚍𝚏ₓ = number of documents containing x\n",
        "  𝙽 = total number of documents\n",
        "\n",
        "TF -> Number of ocurrences of a term in a document\n",
        "IDF -> Importance of the term in the corpus\n",
        "```\n",
        "\n",
        "\n",
        "Tokenize. Attach a unique number to each word.\n"
      ],
      "metadata": {
        "id": "0AG2Jh2gH-Vq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install pyspark"
      ],
      "metadata": {
        "id": "o6C_RJ5FOh1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqjO0nvbSSku",
        "outputId": "460b32ab-76b2-44e2-c16d-270eae9cc45e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necesary libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.ml.feature import NGram\n",
        "from pyspark.ml.feature import StopWordsRemover\n",
        "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
        "from pyspark.ml.feature import HashingTF, IDF\n",
        "from pyspark.ml.feature import CountVectorizer"
      ],
      "metadata": {
        "id": "u-y5YTr0SUS3"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a session\n",
        "spark = SparkSession.builder.appName('nlp').getOrCreate()"
      ],
      "metadata": {
        "id": "aCW88ZyMSibM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create our own dataframe\n",
        "sentenceDataFrame_1 = spark.createDataFrame([\n",
        "    (0, 'Hi I heard about Spark'),\n",
        "    (1, 'I wish java could use case classes'),\n",
        "    (2, 'Logistic,regression,models,are,neat'),\n",
        "], ['id', 'sentence'])"
      ],
      "metadata": {
        "id": "HAnk67cISqPr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the dataframe\n",
        "sen_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FA_9oX8TTDr",
        "outputId": "76b90127-2ac0-4fcb-8565-934c88672625"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+\n",
            "| id|            sentence|\n",
            "+---+--------------------+\n",
            "|  0|Hi I heard about ...|\n",
            "|  1|I wish java could...|\n",
            "|  2|Logistic,regressi...|\n",
            "+---+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create tokenizer objects\n",
        "We'll use a normal tokenizer function and the regex tokenizer"
      ],
      "metadata": {
        "id": "A9Z5QA1sV0p_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize words. Convert into numeric values\n",
        "tokenizer = Tokenizer(inputCol='sentence', outputCol='words')"
      ],
      "metadata": {
        "id": "axnZdsAJTUV6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Regular expression Tokenizer\n",
        "regex_tokenizer = RegexTokenizer(inputCol='sentence', outputCol='words', pattern='\\\\W')"
      ],
      "metadata": {
        "id": "_cCiwwiZTx_Z"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a function to count the total words in the row"
      ],
      "metadata": {
        "id": "zlG_Ui1sV723"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to count words\n",
        "count_tokens = udf(lambda words: len(words), IntegerType())"
      ],
      "metadata": {
        "id": "Qg0kntGrUBoR"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Show tokenized words\n",
        "We'll add a column with the number of words. To do this, we're gonna use the function we just created"
      ],
      "metadata": {
        "id": "fQ6k5IngVfeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize with our tokenizer objects\n",
        "tokenized = tokenizer.transform(sentenceDataFrame_1)\n",
        "regex_tokenized = regex_tokenizer.transform(sentenceDataFrame_1)"
      ],
      "metadata": {
        "id": "p5UJsB5AUXGN"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show tokenized words\n",
        "tokenized.withColumn('tokens', count_tokens(col('words'))).show()\n",
        "\n",
        "regex_tokenized.withColumn('tokens', count_tokens(col('words'))).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zc1h1x-9UeGe",
        "outputId": "87e6e33e-41ee-4f58-a8f8-1bd0713d39b2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+--------------------+------+\n",
            "| id|            sentence|               words|tokens|\n",
            "+---+--------------------+--------------------+------+\n",
            "|  0|Hi I heard about ...|[hi, i, heard, ab...|     5|\n",
            "|  1|I wish java could...|[i, wish, java, c...|     7|\n",
            "|  2|Logistic,regressi...|[logistic,regress...|     1|\n",
            "+---+--------------------+--------------------+------+\n",
            "\n",
            "+---+--------------------+--------------------+------+\n",
            "| id|            sentence|               words|tokens|\n",
            "+---+--------------------+--------------------+------+\n",
            "|  0|Hi I heard about ...|[hi, i, heard, ab...|     5|\n",
            "|  1|I wish java could...|[i, wish, java, c...|     7|\n",
            "|  2|Logistic,regressi...|[logistic, regres...|     5|\n",
            "+---+--------------------+--------------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove words that don't add value"
      ],
      "metadata": {
        "id": "N2xj9awrWpa8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sentence DataFrame\n",
        "sentenceDataFrame_2 = spark.createDataFrame([\n",
        "    (0, ['I', 'saw', 'the', 'green', 'horse']),\n",
        "    (1, ['Mary', 'had', 'a', 'little', 'lamb']),\n",
        "], ['id', 'tokens'])"
      ],
      "metadata": {
        "id": "xoccFMiAVIix"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create remover object\n",
        "remover = StopWordsRemover(inputCol='tokens', outputCol='filtered')"
      ],
      "metadata": {
        "id": "i0P2UgIFWoY2"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove words and show\n",
        "remover.transform(sentenceDataFrame_2).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsW5zp87W5Gq",
        "outputId": "be31e5d7-39c3-4a7d-be5e-968079f80e01"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+--------------------+\n",
            "| id|              tokens|            filtered|\n",
            "+---+--------------------+--------------------+\n",
            "|  0|[I, saw, the, gre...| [saw, green, horse]|\n",
            "|  1|[Mary, had, a, li...|[Mary, little, lamb]|\n",
            "+---+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## N-Gram\n",
        "Sequence of tokens given some integer.\n",
        "Strings of consecutive words determined by the user."
      ],
      "metadata": {
        "id": "SLN2M5cZW_Yk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataframe\n",
        "wordDataFrame_1 = spark.createDataFrame([\n",
        "    (0, ['Hi', 'I', 'heard', 'about', 'Spark']),\n",
        "    (1, ['I', 'wish', 'java', 'could', 'use', 'case', 'classes']),\n",
        "    (2, ['Logistic', 'regression', 'models', 'are', 'neat']),\n",
        "], ['id', 'words'])"
      ],
      "metadata": {
        "id": "nYQD3smlXTwq"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create ngram object\n",
        "ngram = NGram(n=2, inputCol='words', outputCol='grams')"
      ],
      "metadata": {
        "id": "rBM7hnBNXxnh"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngram.transform(wordDataFrame_1).select('grams').show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BQwiAqTX6il",
        "outputId": "950b1263-4acc-4d72-8236-5c4ba065abb7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------------------------+\n",
            "|grams                                                             |\n",
            "+------------------------------------------------------------------+\n",
            "|[Hi I, I heard, heard about, about Spark]                         |\n",
            "|[I wish, wish java, java could, could use, use case, case classes]|\n",
            "|[Logistic regression, regression models, models are, are neat]    |\n",
            "+------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manipulate words with Time Frequency (TF-IDF)"
      ],
      "metadata": {
        "id": "b01a12PU7iti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenize words"
      ],
      "metadata": {
        "id": "NtiC5Fgz8gCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remember our sentence 1\n",
        "sentenceDataFrame_1.show()"
      ],
      "metadata": {
        "id": "Ri8nQwg0X-kv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b35c0664-4b2f-41c2-bb08-ed09b421e3be"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+\n",
            "| id|            sentence|\n",
            "+---+--------------------+\n",
            "|  0|Hi I heard about ...|\n",
            "|  1|I wish java could...|\n",
            "|  2|Logistic,regressi...|\n",
            "+---+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create a tokenizer object\n",
        "tokenizer = Tokenizer(inputCol='sentence', outputCol='words')"
      ],
      "metadata": {
        "id": "eEpCz1XB7-5d"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize sentences\n",
        "words_data = tokenizer.transform(sentenceDataFrame_1)"
      ],
      "metadata": {
        "id": "kXUm72S78HxL"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show our tokenized sentences\n",
        "words_data.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnQ03aSJ8TqJ",
        "outputId": "b9890417-a951-4006-b72d-9dfc6ea7041d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----------------------------------+------------------------------------------+\n",
            "|id |sentence                           |words                                     |\n",
            "+---+-----------------------------------+------------------------------------------+\n",
            "|0  |Hi I heard about Spark             |[hi, i, heard, about, spark]              |\n",
            "|1  |I wish java could use case classes |[i, wish, java, could, use, case, classes]|\n",
            "|2  |Logistic,regression,models,are,neat|[logistic,regression,models,are,neat]     |\n",
            "+---+-----------------------------------+------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grab the Time Frequency (TF)"
      ],
      "metadata": {
        "id": "9OvyWaFx8e5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the first part of the TF-IDF equation\n",
        "hashing_tf = HashingTF(inputCol='words', outputCol='rawFeatures')\n",
        "featurized_data = hashing_tf.transform(words_data)"
      ],
      "metadata": {
        "id": "OzuwjrZa8aPy"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the featurized data\n",
        "featurized_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omNPh-dZ-a3g",
        "outputId": "0223a264-e72b-4c86-f5fe-a8a36d552a19"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+--------------------+--------------------+\n",
            "| id|            sentence|               words|         rawFeatures|\n",
            "+---+--------------------+--------------------+--------------------+\n",
            "|  0|Hi I heard about ...|[hi, i, heard, ab...|(262144,[18700,19...|\n",
            "|  1|I wish java could...|[i, wish, java, c...|(262144,[19036,20...|\n",
            "|  2|Logistic,regressi...|[logistic,regress...|(262144,[11534],[...|\n",
            "+---+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply the Inverse Document Frequency (IDF)\n",
        "\n",
        "Now we'll create the model"
      ],
      "metadata": {
        "id": "IwAm1lAF86pi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the second part of the TF-IDF equation\n",
        "idf = IDF(inputCol='rawFeatures', outputCol='features')"
      ],
      "metadata": {
        "id": "zW-_YJX29YvW"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the TF-IDF model"
      ],
      "metadata": {
        "id": "EgbV1ofW9zVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "idf_model = idf.fit(featurized_data)"
      ],
      "metadata": {
        "id": "28VgnrNe9ing"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rescale our data coming from the TF part into the IDF one\n",
        "rescaled_data = idf_model.transform(featurized_data)"
      ],
      "metadata": {
        "id": "VtSAPNis-Hxj"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the data\n",
        "rescaled_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBjP87ej-m9r",
        "outputId": "6105b9d3-fef4-4eed-d41b-7bb06720361e"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+--------------------+--------------------+--------------------+\n",
            "| id|            sentence|               words|         rawFeatures|            features|\n",
            "+---+--------------------+--------------------+--------------------+--------------------+\n",
            "|  0|Hi I heard about ...|[hi, i, heard, ab...|(262144,[18700,19...|(262144,[18700,19...|\n",
            "|  1|I wish java could...|[i, wish, java, c...|(262144,[19036,20...|(262144,[19036,20...|\n",
            "|  2|Logistic,regressi...|[logistic,regress...|(262144,[11534],[...|(262144,[11534],[...|\n",
            "+---+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the important columns\n",
        "rescaled_data.select('id', 'features').show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQq7lVHr-PYb",
        "outputId": "b80c47d1-1449-40c6-ba9a-b658b72b0339"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|id |features                                                                                                                                                                                      |\n",
            "+---+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|0  |(262144,[18700,19036,33808,66273,173558],[0.6931471805599453,0.28768207245178085,0.6931471805599453,0.6931471805599453,0.6931471805599453])                                                   |\n",
            "|1  |(262144,[19036,20719,55551,58672,98717,109547,192310],[0.28768207245178085,0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453])|\n",
            "|2  |(262144,[11534],[0.6931471805599453])                                                                                                                                                         |\n",
            "+---+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Work with count vectorizer"
      ],
      "metadata": {
        "id": "TA-B11oLD3J-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new DataFrame\n",
        "df = spark.createDataFrame([\n",
        "    (0, 'a b c'.split(' ')),\n",
        "    (1, 'a b b c a'.split(' ')),\n",
        "], ['id', 'words'])"
      ],
      "metadata": {
        "id": "eqE6anLL-UO5"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show data\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anKQWEbrDWi4",
        "outputId": "618874dd-9b3e-4740-b076-1eeb198cfe01"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------------+\n",
            "| id|          words|\n",
            "+---+---------------+\n",
            "|  0|      [a, b, c]|\n",
            "|  1|[a, b, b, c, a]|\n",
            "+---+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a count vectorizer object\n",
        "cv = CountVectorizer(inputCol='words', outputCol='features',\n",
        "                    vocabSize=3, minDF=2.0)"
      ],
      "metadata": {
        "id": "wy3UQyQlDYcn"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit with our data\n",
        "model = cv.fit(df)"
      ],
      "metadata": {
        "id": "qse7Z01gEAFv"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform with our data and get results\n",
        "result = model.transform(df)"
      ],
      "metadata": {
        "id": "ilc7LV4JEGZs"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show data\n",
        "result.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scqQJBEiETqg",
        "outputId": "4e64593c-047b-4f08-d192-9b7477cce70a"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------------+-------------------------+\n",
            "|id |words          |features                 |\n",
            "+---+---------------+-------------------------+\n",
            "|0  |[a, b, c]      |(3,[0,1,2],[1.0,1.0,1.0])|\n",
            "|1  |[a, b, b, c, a]|(3,[0,1,2],[2.0,2.0,1.0])|\n",
            "+---+---------------+-------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vQWuZnwCEXNJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}